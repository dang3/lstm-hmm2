{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '..\\\\..\\\\')\n",
    "\n",
    "import os\n",
    "import data_loader\n",
    "from numpy import trapz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Dropout, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "malware_data_dir = '../../data/'\n",
    "saved_model_path = 'saved_model/'\n",
    "opcode_to_int_path = \"opcodeToInt.txt\"\n",
    "num_unique_opcodes = 50\n",
    "max_opcode_sequence_length = 4000\n",
    "embed_vector_length = 128\n",
    "num_lstm_unit = 16\n",
    "dropout_amt = 0.3\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "test_size= 0.15       # reserve for testing\n",
    "num_families_to_use = 10\n",
    "\n",
    "shutdown = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting list of paths to training data\n",
      "{'winwebsec': 13045263, 'vundo': 6518146, 'zbot': 6348792, 'hotbar': 5904000, 'onlinegames': 5049791, 'renos': 5003745, 'obfuscator': 4798215, 'bho': 4629982, 'zeroaccess': 4476000, 'alureon': 3870723}\n",
      "Finding out how many opcodes to use per family...\n",
      "3870723\n",
      "Generating opcode to int mapping...\n",
      "File saved, done.\n",
      "Loading training data for hotbar\n",
      "Loading training data for renos\n",
      "Loading training data for vundo\n",
      "Loading training data for winwebsec\n",
      "Loading training data for zbot\n",
      "Loading training data for alureon\n",
      "Loading training data for bho\n",
      "Loading training data for obfuscator\n",
      "Loading training data for onlinegames\n",
      "Loading training data for zeroaccess\n",
      "All training data loaded\n"
     ]
    }
   ],
   "source": [
    "raw_train_data = data_loader.getTrainData(malware_data_dir, \n",
    "                                          num_families_to_use, \n",
    "                                          num_unique_opcodes, \n",
    "                                          max_opcode_sequence_length, \n",
    "                                          opcode_to_int_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hotbar', 'renos', 'vundo', 'winwebsec', 'zbot', 'alureon', 'bho', 'obfuscator', 'onlinegames', 'zeroaccess']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "family_names = list(raw_train_data.keys())\n",
    "print(family_names)\n",
    "\n",
    "# Split opcode family data in individual lists\n",
    "train_data = list()\n",
    "for family, data in raw_train_data.items():\n",
    "    train_data.append(data)\n",
    "    \n",
    "# Pad training data to ensure uniformity\n",
    "padded_train_data = list()\n",
    "for family_opcodes in train_data:\n",
    "    padded_sequence = pad_sequences(family_opcodes, \n",
    "                                    maxlen=max_opcode_sequence_length)\n",
    "    padded_train_data.append(padded_sequence)\n",
    "    \n",
    "# Concatenate all training data into 1 long list instead of multiple lists\n",
    "train_data_raw = np.concatenate(padded_train_data)\n",
    "\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "\n",
    "for count, data in enumerate(padded_train_data):\n",
    "    labels_list = np.full(shape=(len(data)), fill_value=count)\n",
    "    train_labels.append(labels_list)\n",
    "\n",
    "train_labels_raw = np.concatenate(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plit into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(train_data_raw, train_labels_raw):\n",
    "    # Split into training and testing data\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(train_data_raw, train_labels_raw, test_size=test_size)\n",
    "\n",
    "    # Make divisible by batch size\n",
    "    num_data_train = int(len(train_data)/batch_size) * batch_size\n",
    "    num_data_test = int(len(test_data)/batch_size) * batch_size\n",
    "\n",
    "    train_data = train_data[:num_data_train]\n",
    "    train_labels = train_labels[:num_data_train]\n",
    "    test_data = test_data[:num_data_test]\n",
    "    test_labels = test_labels[:num_data_test]\n",
    "    \n",
    "    print(\"train_data shape: {}\".format(train_data.shape))\n",
    "    print(\"test_data shape: {}\".format(test_data.shape))\n",
    "    print(\"train_labels shape: {}\".format(train_labels.shape))\n",
    "    print(\"test_labels shape: {}\".format(test_labels.shape))\n",
    "    \n",
    "    return train_data, test_data, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Input(batch_shape=(batch_size, max_opcode_sequence_length), name=\"input\"))\n",
    "    model.add(Embedding(input_dim=num_unique_opcodes+1,\n",
    "                                  output_dim=embed_vector_length,\n",
    "                                  input_length=max_opcode_sequence_length, name=\"embedding\"))\n",
    "    # LSTM 1\n",
    "    model.add(Dropout(dropout_amt, name=\"dropout_1\"))\n",
    "    model.add(LSTM(num_lstm_unit, \n",
    "                   input_shape=(None, max_opcode_sequence_length),\n",
    "                   return_sequences=True,\n",
    "                   name=\"lstm1\"))\n",
    "    # LSTM 2\n",
    "    model.add(Dropout(dropout_amt, name=\"dropout_2\"))\n",
    "    model.add(LSTM(num_lstm_unit*3, \n",
    "                   return_sequences=True,\n",
    "                   name=\"lstm2\"))\n",
    "    # LSTM 3\n",
    "    model.add(Dropout(dropout_amt*2, name=\"dropout_3\"))\n",
    "    model.add(LSTM(num_lstm_unit, \n",
    "                                   name=\"lstm3\"))\n",
    "    model.add(Dense(num_families_to_use, activation='softmax', name=\"dense\"))\n",
    "    optimizer = Adam()\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    #model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape: (8896, 4000)\n",
      "test_data shape: (1536, 4000)\n",
      "train_labels shape: (8896,)\n",
      "test_labels shape: (1536,)\n",
      "Epoch 1/100\n",
      "139/139 [==============================] - 51s 369ms/step - loss: 2.0519 - accuracy: 0.2328\n",
      "Epoch 2/100\n",
      "139/139 [==============================] - 52s 371ms/step - loss: 1.8212 - accuracy: 0.3504\n",
      "Epoch 3/100\n",
      "139/139 [==============================] - 51s 366ms/step - loss: 1.6470 - accuracy: 0.4288\n",
      "Epoch 4/100\n",
      "139/139 [==============================] - 51s 365ms/step - loss: 1.5060 - accuracy: 0.4713\n",
      "Epoch 5/100\n",
      "139/139 [==============================] - 51s 366ms/step - loss: 1.4482 - accuracy: 0.4858\n",
      "Epoch 6/100\n",
      "136/139 [============================>.] - ETA: 1s - loss: 1.3887 - accuracy: 0.5098"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-23f7b8e3ccf1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mmodel_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     history = model_train.fit(x=train_data,\n\u001b[0m\u001b[0;32m     11\u001b[0m                           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(5):\n",
    "    # get train and test data\n",
    "    train_data, test_data, train_labels, test_labels = split_data(train_data_raw, train_labels_raw)\n",
    "    \n",
    "    # train model\n",
    "    model_train = create_model()\n",
    "    early_stopping = EarlyStopping(monitor='loss', verbose=1, patience=2)\n",
    "    history = model_train.fit(x=train_data,\n",
    "                          y=train_labels,\n",
    "                          batch_size=batch_size,\n",
    "                          callbacks = [early_stopping],\n",
    "                          epochs=num_epochs,)\n",
    "    \n",
    "    # evaluate\n",
    "    model_evaluate = create_model()\n",
    "    model_evaluate.set_weights(model_train.get_weights())\n",
    "\n",
    "    scores = model_evaluate.evaluate(test_data, test_labels, verbose=0, callbacks = [early_stopping])\n",
    "    accuracy = scores[1]*100\n",
    "    print(accuracy)\n",
    "    results.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open(\"accuracyResults.txt\", 'w') as f:\n",
    "#     for x in results:\n",
    "#         f.write(str(x) + \"\\n\")\n",
    "\n",
    "# os.system('shutdown -s')\n",
    "\n",
    "# model_train.save_weights(saved_model_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use History to plot and accuracy throughout training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluate = create_model()\n",
    "model_evaluate.set_weights(model_train.get_weights())\n",
    "\n",
    "scores = model_evaluate.evaluate(test_data, test_labels, verbose=0, callbacks = [early_stopping])\n",
    "accuracy = scores[1]*100\n",
    "print(\"Accuracy: %0.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model From Save and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.load_weights(saved_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_set, test_labels, verbose=0)\n",
    "accuracy = scores[1]*100\n",
    "print(\"Accuracy: %0.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate winwebsec and zbot test data\n",
    "winwebsec_test_data = []\n",
    "zbot_test_data = []\n",
    "\n",
    "for i in range(len(test_labels)):\n",
    "    if test_labels[i] == 0:\n",
    "        winwebsec_test_data.append(test_set[i])\n",
    "    else:\n",
    "        zbot_test_data.append(test_set[i])\n",
    "        \n",
    "winwebsec_test_data = np.asarray(winwebsec_test_data[:192])\n",
    "zbot_test_data = np.asarray(zbot_test_data[:128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(winwebsec_test_data.shape)\n",
    "print(zbot_test_data.shape)\n",
    "\n",
    "\n",
    "winwebsecY = model.predict(winwebsec_test_data)\n",
    "winwebsecX = [i+1 for i in range(len(winwebsec_test_data))]\n",
    "\n",
    "zbotY = model.predict(zbot_test_data)\n",
    "zbotX = [i+1 for i in range(len(zbot_test_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(100)\n",
    "f = plt.scatter(winwebsecX, winwebsecY, marker='o',\n",
    "                c='darkblue', s=30, label=\"winwebsec\")\n",
    "plt.scatter(zbotX, zbotY, marker='o', c='red', s=30, label=\"zbot\")\n",
    "plt.title(\"Winwebsec vs. Zbot LSTM Prediction Scatter Plot\",\n",
    "          fontsize=18, wrap=True)\n",
    "f.axes.get_xaxis().set_visible(False)\n",
    "plt.ylabel(\"Prediction\", fontsize=15)\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortByFirstItem(item):\n",
    "    return item[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winwebsecROC = [(data, \"winwebsec\") for data in winwebsecY]\n",
    "zbotROC = [(data, \"zbot\") for data in zbotY]\n",
    "\n",
    "zbotROC.sort(key=sortByFirstItem)\n",
    "winwebsecROC.sort(key=sortByFirstItem)\n",
    "\n",
    "dataROC = zbotROC + winwebsecROC\n",
    "dataROC.sort(key=sortByFirstItem, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_TPR_FPR(thresholdLine, dataROC):\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "\n",
    "    for data in dataROC:\n",
    "        yVal = data[0]\n",
    "        family = data[1]\n",
    "\n",
    "        if family == \"winwebsec\":\n",
    "            if yVal < thresholdLine:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        elif family == \"zbot\":\n",
    "            if yVal > thresholdLine:\n",
    "                TN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "    TPR = TP/(TP+FN)\n",
    "    FPR = 1 - (TN/(TN+FP))\n",
    "\n",
    "    return TPR, FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAUC(rocData):\n",
    "    sum = 0\n",
    "\n",
    "    # initialization\n",
    "    prevX = -1\n",
    "    prevY = -1\n",
    "\n",
    "    for points in rocData:\n",
    "        curX = points[0]\n",
    "        curY = points[1]\n",
    "\n",
    "        # Skip for first point\n",
    "        if prevX != -1 and prevY != -1:\n",
    "            # check if rectangle\n",
    "            if prevY == curY:\n",
    "                sum += abs(curX - prevX) * prevY\n",
    "            # check if trapezoid\n",
    "            else:\n",
    "                sum += (curY + prevY) * abs(curX - prevX) * 0.5\n",
    "\n",
    "        prevX = curX\n",
    "        prevY = curY\n",
    "\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocX = list()  # used to plot\n",
    "rocY = list()  # used to plot\n",
    "rocData = list()    # used to calculate AUC\n",
    "\n",
    "for entry in dataROC:\n",
    "    thresholdLine = entry[0]\n",
    "    TPR, FPR = calculate_TPR_FPR(thresholdLine, dataROC)\n",
    "\n",
    "    rocX.append(FPR)\n",
    "    rocY.append(TPR)\n",
    "    rocData.append([FPR, TPR])\n",
    "\n",
    "rocData.sort(key=lambda item: (item[0], item[1]), reverse=True)\n",
    "\n",
    "AUC = round(calculateAUC(rocData), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "\n",
    "plt.figure(200)\n",
    "plt.plot(rocX, rocY, marker=\".\", markersize=8)\n",
    "plt.title(\"Winwebsec vs. Zbot LSTM Log Probability ROC\", fontsize=18)\n",
    "plt.xlabel(\"FPR\", fontsize=15)\n",
    "plt.ylabel(\"TPR\", fontsize=15)\n",
    "plt.grid()\n",
    "plt.text(x=0.75, y=0, s=\"AUC: {0}\".format(AUC), fontsize=14, bbox=props)\n",
    "\n",
    "# show plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shutdown:\n",
    "    os.system('shutdown -s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
