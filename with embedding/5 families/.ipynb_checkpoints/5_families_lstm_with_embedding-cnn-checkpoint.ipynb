{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '..\\\\..\\\\')\n",
    "\n",
    "import os\n",
    "import data_loader\n",
    "from numpy import trapz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Dropout, Embedding, Conv1D,MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "malware_data_dir = '../../data/'\n",
    "saved_model_path = 'saved_model/'\n",
    "opcode_to_int_path = \"opcodeToInt.txt\"\n",
    "num_unique_opcodes = 30\n",
    "max_opcode_sequence_length = 2000\n",
    "embed_vector_length = 128\n",
    "num_lstm_unit = 16\n",
    "dropout_amt = 0.3\n",
    "batch_size = 64\n",
    "num_epochs = 20\n",
    "test_size= 0.15       # reserve for testing\n",
    "num_families_to_use = 5\n",
    "\n",
    "shutdown = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting list of paths to training data\n",
      "{'winwebsec': 6862260, 'vundo': 3492760, 'zbot': 3256944, 'hotbar': 2952000, 'renos': 2612858}\n",
      "Loading training data for hotbar\n",
      "Loading training data for renos\n",
      "Loading training data for vundo\n",
      "Loading training data for winwebsec\n",
      "Loading training data for zbot\n",
      "All training data loaded\n"
     ]
    }
   ],
   "source": [
    "raw_train_data = data_loader.getTrainData(malware_data_dir, \n",
    "                                          num_families_to_use, \n",
    "                                          num_unique_opcodes, \n",
    "                                          max_opcode_sequence_length, \n",
    "                                          opcode_to_int_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hotbar', 'renos', 'vundo', 'winwebsec', 'zbot']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "family_names = list(raw_train_data.keys())\n",
    "print(family_names)\n",
    "\n",
    "# Split opcode family data in individual lists\n",
    "train_data = list()\n",
    "for family, data in raw_train_data.items():\n",
    "    train_data.append(data)\n",
    "    \n",
    "# Pad training data to ensure uniformity\n",
    "padded_train_data = list()\n",
    "for family_opcodes in train_data:\n",
    "    padded_sequence = pad_sequences(family_opcodes, \n",
    "                                    maxlen=max_opcode_sequence_length)\n",
    "    padded_train_data.append(padded_sequence)\n",
    "    \n",
    "# Concatenate all training data into 1 long list instead of multiple lists\n",
    "train_data_raw = np.concatenate(padded_train_data)\n",
    "\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "\n",
    "for count, data in enumerate(padded_train_data):\n",
    "    labels_list = np.full(shape=(len(data)), fill_value=count)\n",
    "    train_labels.append(labels_list)\n",
    "\n",
    "train_labels_raw = np.concatenate(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(train_data_raw, train_labels_raw):\n",
    "    # Split into training and testing data\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(train_data_raw, train_labels_raw, test_size=test_size)\n",
    "\n",
    "    # Make divisible by batch size\n",
    "    num_data_train = int(len(train_data)/batch_size) * batch_size\n",
    "    num_data_test = int(len(test_data)/batch_size) * batch_size\n",
    "\n",
    "    train_data = train_data[:num_data_train]\n",
    "    train_labels = train_labels[:num_data_train]\n",
    "    test_data = test_data[:num_data_test]\n",
    "    test_labels = test_labels[:num_data_test]\n",
    "    \n",
    "#     print(\"train_data shape: {}\".format(train_data.shape))\n",
    "#     print(\"test_data shape: {}\".format(test_data.shape))\n",
    "#     print(\"train_labels shape: {}\".format(train_labels.shape))\n",
    "#     print(\"test_labels shape: {}\".format(test_labels.shape))\n",
    "    \n",
    "    return train_data, test_data, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Input(batch_shape=(batch_size, max_opcode_sequence_length), name=\"input\"))\n",
    "    model.add(Embedding(input_dim=num_unique_opcodes+1,\n",
    "                                  output_dim=embed_vector_length,\n",
    "                                  input_length=max_opcode_sequence_length, name=\"embedding\"))\n",
    "    model.add(Conv1D(filters=embed_vector_length, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(LSTM(num_lstm_unit, \n",
    "                   input_shape=(None, max_opcode_sequence_length),\n",
    "                   return_sequences=True,\n",
    "                   name=\"lstm1\"))\n",
    "    model.add(Dense(5, activation='softmax', name=\"dense\"))\n",
    "    optimizer = Adam()\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    #model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape: (5760, 2000)\n",
      "test_data shape: (960, 2000)\n",
      "train_labels shape: (5760,)\n",
      "test_labels shape: (960,)\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - 17s 188ms/step - loss: 1.3189 - accuracy: 0.4748\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 17s 185ms/step - loss: 0.9639 - accuracy: 0.6641\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 17s 184ms/step - loss: 0.9552 - accuracy: 0.6809s -\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - 16s 183ms/step - loss: 0.7643 - accuracy: 0.7497\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - 16s 182ms/step - loss: 0.9904 - accuracy: 0.6464\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - 16s 183ms/step - loss: 0.7416 - accuracy: 0.7628\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - 17s 184ms/step - loss: 0.7051 - accuracy: 0.7726\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - 17s 186ms/step - loss: 0.6629 - accuracy: 0.7898s - loss: 0.6665 - accura\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - 17s 189ms/step - loss: 0.6722 - accuracy: 0.7762\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - 17s 194ms/step - loss: 0.6651 - accuracy: 0.7852\n",
      "Epoch 00010: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (64, 2000) for input Tensor(\"input_1:0\", shape=(64, 2000), dtype=float32), but it was called on an input with incompatible shape (32, 2000).\n",
      "WARNING:tensorflow:Model was constructed with shape (64, 2000) for input Tensor(\"input_1:0\", shape=(64, 2000), dtype=float32), but it was called on an input with incompatible shape (32, 2000).\n",
      "train_data shape: (5760, 2000)\n",
      "test_data shape: (960, 2000)\n",
      "train_labels shape: (5760,)\n",
      "test_labels shape: (960,)\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - 17s 190ms/step - loss: 1.3139 - accuracy: 0.4806s - loss: 1.3241 \n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 17s 189ms/step - loss: 1.0780 - accuracy: 0.6080\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 17s 189ms/step - loss: 0.9524 - accuracy: 0.6573\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - 17s 188ms/step - loss: 0.9301 - accuracy: 0.6736\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - 17s 190ms/step - loss: 0.8811 - accuracy: 0.6953\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - 17s 189ms/step - loss: 0.9252 - accuracy: 0.6729\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - 17s 193ms/step - loss: 0.8395 - accuracy: 0.7078\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - 17s 187ms/step - loss: 0.8296 - accuracy: 0.6997\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - 17s 187ms/step - loss: 0.7846 - accuracy: 0.7314\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - 17s 186ms/step - loss: 0.7097 - accuracy: 0.7536s - loss: 0.7114 - accuracy\n",
      "Epoch 11/20\n",
      "90/90 [==============================] - 17s 188ms/step - loss: 0.7057 - accuracy: 0.7698\n",
      "Epoch 12/20\n",
      "90/90 [==============================] - 17s 188ms/step - loss: 0.7646 - accuracy: 0.7417s - loss: 0.7526 - \n",
      "Epoch 13/20\n",
      "90/90 [==============================] - 17s 186ms/step - loss: 0.8044 - accuracy: 0.7238\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (64, 2000) for input Tensor(\"input_3:0\", shape=(64, 2000), dtype=float32), but it was called on an input with incompatible shape (32, 2000).\n",
      "WARNING:tensorflow:Model was constructed with shape (64, 2000) for input Tensor(\"input_3:0\", shape=(64, 2000), dtype=float32), but it was called on an input with incompatible shape (32, 2000).\n",
      "train_data shape: (5760, 2000)\n",
      "test_data shape: (960, 2000)\n",
      "train_labels shape: (5760,)\n",
      "test_labels shape: (960,)\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - 17s 185ms/step - loss: 1.3361 - accuracy: 0.4595\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 17s 186ms/step - loss: 1.0059 - accuracy: 0.6307\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 17s 186ms/step - loss: 0.8992 - accuracy: 0.6538\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - 17s 187ms/step - loss: 0.8149 - accuracy: 0.6896\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - 17s 187ms/step - loss: 0.7772 - accuracy: 0.6967s - loss: 0.7\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - 17s 187ms/step - loss: 0.7330 - accuracy: 0.7217\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - 17s 190ms/step - loss: 0.6959 - accuracy: 0.7365\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - 17s 190ms/step - loss: 0.6907 - accuracy: 0.7424\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - 17s 191ms/step - loss: 0.6532 - accuracy: 0.7595\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - 17s 185ms/step - loss: 0.7278 - accuracy: 0.7377\n",
      "Epoch 11/20\n",
      "90/90 [==============================] - 17s 185ms/step - loss: 0.6709 - accuracy: 0.7766\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (64, 2000) for input Tensor(\"input_5:0\", shape=(64, 2000), dtype=float32), but it was called on an input with incompatible shape (32, 2000).\n",
      "WARNING:tensorflow:Model was constructed with shape (64, 2000) for input Tensor(\"input_5:0\", shape=(64, 2000), dtype=float32), but it was called on an input with incompatible shape (32, 2000).\n",
      "train_data shape: (5760, 2000)\n",
      "test_data shape: (960, 2000)\n",
      "train_labels shape: (5760,)\n",
      "test_labels shape: (960,)\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - 18s 196ms/step - loss: 1.3708 - accuracy: 0.4547\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 17s 187ms/step - loss: 1.0907 - accuracy: 0.6019\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 17s 185ms/step - loss: 0.9706 - accuracy: 0.6253\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - 17s 185ms/step - loss: 0.9077 - accuracy: 0.6345\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - 17s 185ms/step - loss: 0.8695 - accuracy: 0.6434\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - 17s 185ms/step - loss: 0.8341 - accuracy: 0.6630\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - 17s 186ms/step - loss: 0.8143 - accuracy: 0.6748\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - 17s 185ms/step - loss: 0.7770 - accuracy: 0.6882\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - 17s 186ms/step - loss: 0.7440 - accuracy: 0.7061\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - 17s 188ms/step - loss: 0.7489 - accuracy: 0.7167\n",
      "Epoch 11/20\n",
      "90/90 [==============================] - 17s 188ms/step - loss: 0.7228 - accuracy: 0.7427\n",
      "Epoch 12/20\n",
      "90/90 [==============================] - 17s 188ms/step - loss: 0.6867 - accuracy: 0.7599\n",
      "Epoch 13/20\n",
      "90/90 [==============================] - 17s 186ms/step - loss: 0.6270 - accuracy: 0.7816\n",
      "Epoch 14/20\n",
      "90/90 [==============================] - 17s 186ms/step - loss: 0.6250 - accuracy: 0.7858\n",
      "Epoch 15/20\n",
      "90/90 [==============================] - 17s 186ms/step - loss: 0.6094 - accuracy: 0.7878\n",
      "Epoch 16/20\n",
      "90/90 [==============================] - 17s 186ms/step - loss: 0.5786 - accuracy: 0.8031\n",
      "Epoch 17/20\n",
      "90/90 [==============================] - 17s 186ms/step - loss: 0.6028 - accuracy: 0.7960\n",
      "Epoch 18/20\n",
      "90/90 [==============================] - 17s 186ms/step - loss: 0.6519 - accuracy: 0.7750\n",
      "Epoch 00018: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (64, 2000) for input Tensor(\"input_7:0\", shape=(64, 2000), dtype=float32), but it was called on an input with incompatible shape (32, 2000).\n",
      "WARNING:tensorflow:Model was constructed with shape (64, 2000) for input Tensor(\"input_7:0\", shape=(64, 2000), dtype=float32), but it was called on an input with incompatible shape (32, 2000).\n",
      "train_data shape: (5760, 2000)\n",
      "test_data shape: (960, 2000)\n",
      "train_labels shape: (5760,)\n",
      "test_labels shape: (960,)\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - 17s 189ms/step - loss: 1.3251 - accuracy: 0.4941\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 17s 189ms/step - loss: 1.0610 - accuracy: 0.6168\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 17s 190ms/step - loss: 1.0252 - accuracy: 0.6266s - loss: 1.0283 - accuracy: \n",
      "Epoch 4/20\n",
      "90/90 [==============================] - 17s 187ms/step - loss: 0.9203 - accuracy: 0.6606\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - 17s 190ms/step - loss: 0.9132 - accuracy: 0.6606\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - 17s 189ms/step - loss: 0.8821 - accuracy: 0.6689\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - 17s 189ms/step - loss: 0.9437 - accuracy: 0.6392\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - 17s 185ms/step - loss: 0.9425 - accuracy: 0.6568\n",
      "Epoch 00008: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (64, 2000) for input Tensor(\"input_9:0\", shape=(64, 2000), dtype=float32), but it was called on an input with incompatible shape (32, 2000).\n",
      "WARNING:tensorflow:Model was constructed with shape (64, 2000) for input Tensor(\"input_9:0\", shape=(64, 2000), dtype=float32), but it was called on an input with incompatible shape (32, 2000).\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(5):\n",
    "    # get train and test data\n",
    "    train_data, test_data, train_labels, test_labels = split_data(train_data_raw, train_labels_raw)\n",
    "    \n",
    "    # train model\n",
    "    model_train = create_model()\n",
    "    early_stopping = EarlyStopping(monitor='loss', verbose=1, patience=2)\n",
    "    history = model_train.fit(x=train_data,\n",
    "                          y=train_labels,\n",
    "                          batch_size=batch_size,\n",
    "                          callbacks = [early_stopping],\n",
    "                          epochs=num_epochs,)\n",
    "    \n",
    "    # evaluate\n",
    "    model_evaluate = create_model()\n",
    "    model_evaluate.set_weights(model_train.get_weights())\n",
    "\n",
    "    scores = model_evaluate.evaluate(test_data, test_labels, verbose=0, callbacks = [early_stopping])\n",
    "    accuracy = scores[1]*100\n",
    "    results.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.52083134651184\n",
      "77.08333134651184\n",
      "78.02083492279053\n",
      "79.6875\n",
      "68.02083253860474\n"
     ]
    }
   ],
   "source": [
    "for x in results:\n",
    "    print(x)\n",
    "\n",
    "# model_train.save_weights(saved_model_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use History to plot and accuracy throughout training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.3251057863235474,\n",
       "  1.0609724521636963,\n",
       "  1.0251877307891846,\n",
       "  0.9202626347541809,\n",
       "  0.9131650924682617,\n",
       "  0.8820965886116028,\n",
       "  0.9437202215194702,\n",
       "  0.9425027370452881],\n",
       " 'accuracy': [0.4940972328186035,\n",
       "  0.6168403029441833,\n",
       "  0.6265624761581421,\n",
       "  0.6605902910232544,\n",
       "  0.6605902910232544,\n",
       "  0.6689236164093018,\n",
       "  0.6392360925674438,\n",
       "  0.6567708253860474]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (64, 2000) for input Tensor(\"input_10:0\", shape=(64, 2000), dtype=float32), but it was called on an input with incompatible shape (32, 2000).\n",
      "WARNING:tensorflow:Model was constructed with shape (64, 2000) for input Tensor(\"input_10:0\", shape=(64, 2000), dtype=float32), but it was called on an input with incompatible shape (32, 2000).\n",
      "Accuracy: 68.02%\n"
     ]
    }
   ],
   "source": [
    "model_evaluate = create_model()\n",
    "model_evaluate.set_weights(model_train.get_weights())\n",
    "\n",
    "scores = model_evaluate.evaluate(test_data, test_labels, verbose=0, callbacks = [early_stopping])\n",
    "accuracy = scores[1]*100\n",
    "print(\"Accuracy: %0.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model From Save and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x23e034627f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.load_weights(saved_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e5c0a4da9f81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: %0.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_set' is not defined"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_set, test_labels, verbose=0)\n",
    "accuracy = scores[1]*100\n",
    "print(\"Accuracy: %0.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate winwebsec and zbot test data\n",
    "winwebsec_test_data = []\n",
    "zbot_test_data = []\n",
    "\n",
    "for i in range(len(test_labels)):\n",
    "    if test_labels[i] == 0:\n",
    "        winwebsec_test_data.append(test_set[i])\n",
    "    else:\n",
    "        zbot_test_data.append(test_set[i])\n",
    "        \n",
    "winwebsec_test_data = np.asarray(winwebsec_test_data[:192])\n",
    "zbot_test_data = np.asarray(zbot_test_data[:128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(winwebsec_test_data.shape)\n",
    "print(zbot_test_data.shape)\n",
    "\n",
    "\n",
    "winwebsecY = model.predict(winwebsec_test_data)\n",
    "winwebsecX = [i+1 for i in range(len(winwebsec_test_data))]\n",
    "\n",
    "zbotY = model.predict(zbot_test_data)\n",
    "zbotX = [i+1 for i in range(len(zbot_test_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(100)\n",
    "f = plt.scatter(winwebsecX, winwebsecY, marker='o',\n",
    "                c='darkblue', s=30, label=\"winwebsec\")\n",
    "plt.scatter(zbotX, zbotY, marker='o', c='red', s=30, label=\"zbot\")\n",
    "plt.title(\"Winwebsec vs. Zbot LSTM Prediction Scatter Plot\",\n",
    "          fontsize=18, wrap=True)\n",
    "f.axes.get_xaxis().set_visible(False)\n",
    "plt.ylabel(\"Prediction\", fontsize=15)\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortByFirstItem(item):\n",
    "    return item[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winwebsecROC = [(data, \"winwebsec\") for data in winwebsecY]\n",
    "zbotROC = [(data, \"zbot\") for data in zbotY]\n",
    "\n",
    "zbotROC.sort(key=sortByFirstItem)\n",
    "winwebsecROC.sort(key=sortByFirstItem)\n",
    "\n",
    "dataROC = zbotROC + winwebsecROC\n",
    "dataROC.sort(key=sortByFirstItem, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_TPR_FPR(thresholdLine, dataROC):\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "\n",
    "    for data in dataROC:\n",
    "        yVal = data[0]\n",
    "        family = data[1]\n",
    "\n",
    "        if family == \"winwebsec\":\n",
    "            if yVal < thresholdLine:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        elif family == \"zbot\":\n",
    "            if yVal > thresholdLine:\n",
    "                TN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "    TPR = TP/(TP+FN)\n",
    "    FPR = 1 - (TN/(TN+FP))\n",
    "\n",
    "    return TPR, FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAUC(rocData):\n",
    "    sum = 0\n",
    "\n",
    "    # initialization\n",
    "    prevX = -1\n",
    "    prevY = -1\n",
    "\n",
    "    for points in rocData:\n",
    "        curX = points[0]\n",
    "        curY = points[1]\n",
    "\n",
    "        # Skip for first point\n",
    "        if prevX != -1 and prevY != -1:\n",
    "            # check if rectangle\n",
    "            if prevY == curY:\n",
    "                sum += abs(curX - prevX) * prevY\n",
    "            # check if trapezoid\n",
    "            else:\n",
    "                sum += (curY + prevY) * abs(curX - prevX) * 0.5\n",
    "\n",
    "        prevX = curX\n",
    "        prevY = curY\n",
    "\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocX = list()  # used to plot\n",
    "rocY = list()  # used to plot\n",
    "rocData = list()    # used to calculate AUC\n",
    "\n",
    "for entry in dataROC:\n",
    "    thresholdLine = entry[0]\n",
    "    TPR, FPR = calculate_TPR_FPR(thresholdLine, dataROC)\n",
    "\n",
    "    rocX.append(FPR)\n",
    "    rocY.append(TPR)\n",
    "    rocData.append([FPR, TPR])\n",
    "\n",
    "rocData.sort(key=lambda item: (item[0], item[1]), reverse=True)\n",
    "\n",
    "AUC = round(calculateAUC(rocData), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "\n",
    "plt.figure(200)\n",
    "plt.plot(rocX, rocY, marker=\".\", markersize=8)\n",
    "plt.title(\"Winwebsec vs. Zbot LSTM Log Probability ROC\", fontsize=18)\n",
    "plt.xlabel(\"FPR\", fontsize=15)\n",
    "plt.ylabel(\"TPR\", fontsize=15)\n",
    "plt.grid()\n",
    "plt.text(x=0.75, y=0, s=\"AUC: {0}\".format(AUC), fontsize=14, bbox=props)\n",
    "\n",
    "# show plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shutdown:\n",
    "    os.system('shutdown -s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
