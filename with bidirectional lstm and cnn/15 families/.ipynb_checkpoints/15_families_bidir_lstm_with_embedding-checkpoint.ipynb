{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '..\\\\..\\\\')\n",
    "\n",
    "import os\n",
    "import data_loader\n",
    "from numpy import trapz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Dropout, Embedding, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "malware_data_dir = '../../data/'\n",
    "saved_model_path = 'saved_model/'\n",
    "opcode_to_int_path = \"opcodeToInt.txt\"\n",
    "num_unique_opcodes = 30\n",
    "max_opcode_sequence_length = 2000\n",
    "embed_vector_length = 128\n",
    "num_lstm_unit = 16\n",
    "dropout_amt = 0.3\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "test_size= 0.15       # reserve for testing\n",
    "num_families_to_use = 15\n",
    "\n",
    "shutdown = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting list of paths to training data\n",
      "{'winwebsec': 6862260, 'vundo': 3492760, 'zbot': 3256944, 'hotbar': 2952000, 'renos': 2612858, 'onlinegames': 2554166, 'obfuscator': 2502965, 'bho': 2315982, 'alureon': 2287866, 'zeroaccess': 2238000, 'delfinject': 2167855, 'startpage': 2164599, 'adload': 2088000, 'fakerean': 2082110, 'cycbot': 2058000}\n",
      "Finding out how many opcodes to use per family...\n",
      "2058000\n",
      "Generating opcode to int mapping...\n",
      "File saved, done.\n",
      "Loading training data for hotbar\n",
      "Loading training data for renos\n",
      "Loading training data for vundo\n",
      "Loading training data for winwebsec\n",
      "Loading training data for zbot\n",
      "Loading training data for alureon\n",
      "Loading training data for bho\n",
      "Loading training data for obfuscator\n",
      "Loading training data for onlinegames\n",
      "Loading training data for zeroaccess\n",
      "Loading training data for adload\n",
      "Loading training data for cycbot\n",
      "Loading training data for delfinject\n",
      "Loading training data for fakerean\n",
      "Loading training data for startpage\n",
      "All training data loaded\n"
     ]
    }
   ],
   "source": [
    "raw_train_data = data_loader.getTrainData(malware_data_dir, \n",
    "                                          num_families_to_use, \n",
    "                                          num_unique_opcodes, \n",
    "                                          max_opcode_sequence_length, \n",
    "                                          opcode_to_int_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hotbar', 'renos', 'vundo', 'winwebsec', 'zbot', 'alureon', 'bho', 'obfuscator', 'onlinegames', 'zeroaccess', 'adload', 'cycbot', 'delfinject', 'fakerean', 'startpage']\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "family_names = list(raw_train_data.keys())\n",
    "print(family_names)\n",
    "\n",
    "# Split opcode family data in individual lists\n",
    "train_data = list()\n",
    "for family, data in raw_train_data.items():\n",
    "    train_data.append(data)\n",
    "    \n",
    "# Pad training data to ensure uniformity\n",
    "padded_train_data = list()\n",
    "for family_opcodes in train_data:\n",
    "    padded_sequence = pad_sequences(family_opcodes, \n",
    "                                    maxlen=max_opcode_sequence_length)\n",
    "    padded_train_data.append(padded_sequence)\n",
    "    \n",
    "# Concatenate all training data into 1 long list instead of multiple lists\n",
    "train_data_raw = np.concatenate(padded_train_data)\n",
    "\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "\n",
    "for count, data in enumerate(padded_train_data):\n",
    "    labels_list = np.full(shape=(len(data)), fill_value=count)\n",
    "    train_labels.append(labels_list)\n",
    "\n",
    "train_labels_raw = np.concatenate(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(train_data_raw, train_labels_raw):\n",
    "    # Split into training and testing data\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(train_data_raw, train_labels_raw, test_size=test_size)\n",
    "\n",
    "    # Make divisible by batch size\n",
    "    num_data_train = int(len(train_data)/batch_size) * batch_size\n",
    "    num_data_test = int(len(test_data)/batch_size) * batch_size\n",
    "\n",
    "    train_data = train_data[:num_data_train]\n",
    "    train_labels = train_labels[:num_data_train]\n",
    "    test_data = test_data[:num_data_test]\n",
    "    test_labels = test_labels[:num_data_test]\n",
    "    \n",
    "#     print(\"train_data shape: {}\".format(train_data.shape))\n",
    "#     print(\"test_data shape: {}\".format(test_data.shape))\n",
    "#     print(\"train_labels shape: {}\".format(train_labels.shape))\n",
    "#     print(\"test_labels shape: {}\".format(test_labels.shape))\n",
    "    \n",
    "    return train_data, test_data, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Input(batch_shape=(batch_size, max_opcode_sequence_length), name=\"input\"))\n",
    "    model.add(Embedding(input_dim=num_unique_opcodes+1,\n",
    "                        output_dim=embed_vector_length,\n",
    "                        input_length=max_opcode_sequence_length, name=\"embedding\"))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(num_lstm_unit), input_shape=(None, max_opcode_sequence_length)))\n",
    "\n",
    "    model.add(Dense(num_families_to_use, activation='softmax', name=\"dense\"))\n",
    "    optimizer = Adam()\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (32, 2000, 128)           3968      \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (32, 32)                  18560     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 15)                  495       \n",
      "=================================================================\n",
      "Total params: 23,023\n",
      "Trainable params: 23,023\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "571/571 [==============================] - 65s 113ms/step - loss: 1.5896 - accuracy: 0.5400\n",
      "Epoch 2/100\n",
      "571/571 [==============================] - 65s 113ms/step - loss: 1.0603 - accuracy: 0.7006\n",
      "Epoch 3/100\n",
      "571/571 [==============================] - 65s 113ms/step - loss: 0.9910 - accuracy: 0.7110\n",
      "Epoch 4/100\n",
      "571/571 [==============================] - 65s 113ms/step - loss: 0.9261 - accuracy: 0.7220\n",
      "Epoch 5/100\n",
      "571/571 [==============================] - 65s 113ms/step - loss: 0.8379 - accuracy: 0.7519\n",
      "Epoch 6/100\n",
      "571/571 [==============================] - 65s 113ms/step - loss: 0.7851 - accuracy: 0.7682\n",
      "Epoch 7/100\n",
      "571/571 [==============================] - 65s 113ms/step - loss: 0.7499 - accuracy: 0.7803\n",
      "Epoch 8/100\n",
      "571/571 [==============================] - 65s 113ms/step - loss: 0.7459 - accuracy: 0.7806\n",
      "Epoch 9/100\n",
      "571/571 [==============================] - 65s 113ms/step - loss: 0.7755 - accuracy: 0.7683\n",
      "Epoch 10/100\n",
      "571/571 [==============================] - 65s 113ms/step - loss: 0.7101 - accuracy: 0.7904\n",
      "Epoch 11/100\n",
      "571/571 [==============================] - 65s 113ms/step - loss: 0.8824 - accuracy: 0.7491\n",
      "Epoch 12/100\n",
      "571/571 [==============================] - 65s 113ms/step - loss: 0.7749 - accuracy: 0.7744\n",
      "Epoch 00012: early stopping\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (32, 2000, 128)           3968      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (32, 32)                  18560     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 15)                  495       \n",
      "=================================================================\n",
      "Total params: 23,023\n",
      "Trainable params: 23,023\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "78.84374856948853\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (32, 2000, 128)           3968      \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (32, 32)                  18560     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 15)                  495       \n",
      "=================================================================\n",
      "Total params: 23,023\n",
      "Trainable params: 23,023\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "571/571 [==============================] - 65s 113ms/step - loss: 1.6460 - accuracy: 0.5170\n",
      "Epoch 2/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 1.2126 - accuracy: 0.6471\n",
      "Epoch 3/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 1.0396 - accuracy: 0.6986\n",
      "Epoch 4/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.9579 - accuracy: 0.7197\n",
      "Epoch 5/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.8957 - accuracy: 0.7334\n",
      "Epoch 6/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.9425 - accuracy: 0.7200\n",
      "Epoch 7/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.9782 - accuracy: 0.7017\n",
      "Epoch 00007: early stopping\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (32, 2000, 128)           3968      \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (32, 32)                  18560     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 15)                  495       \n",
      "=================================================================\n",
      "Total params: 23,023\n",
      "Trainable params: 23,023\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "73.37499856948853\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (32, 2000, 128)           3968      \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (32, 32)                  18560     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 15)                  495       \n",
      "=================================================================\n",
      "Total params: 23,023\n",
      "Trainable params: 23,023\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 1.5777 - accuracy: 0.5423\n",
      "Epoch 2/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 1.2123 - accuracy: 0.6474\n",
      "Epoch 3/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 1.0461 - accuracy: 0.6984\n",
      "Epoch 4/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.9670 - accuracy: 0.7173\n",
      "Epoch 5/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 1.0164 - accuracy: 0.6945\n",
      "Epoch 6/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.9261 - accuracy: 0.7190\n",
      "Epoch 7/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.8667 - accuracy: 0.7426\n",
      "Epoch 8/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.8530 - accuracy: 0.7514\n",
      "Epoch 9/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.8210 - accuracy: 0.7600\n",
      "Epoch 10/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.7858 - accuracy: 0.7709\n",
      "Epoch 11/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.7662 - accuracy: 0.7777\n",
      "Epoch 12/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.8120 - accuracy: 0.7605\n",
      "Epoch 13/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.7502 - accuracy: 0.7811\n",
      "Epoch 14/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.7008 - accuracy: 0.7956\n",
      "Epoch 15/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.7340 - accuracy: 0.7844\n",
      "Epoch 16/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.6987 - accuracy: 0.7969\n",
      "Epoch 17/100\n",
      "571/571 [==============================] - 66s 115ms/step - loss: 0.6545 - accuracy: 0.8101\n",
      "Epoch 18/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.6431 - accuracy: 0.8130\n",
      "Epoch 19/100\n",
      "571/571 [==============================] - 65s 113ms/step - loss: 0.6389 - accuracy: 0.8126\n",
      "Epoch 20/100\n",
      "571/571 [==============================] - 66s 115ms/step - loss: 0.6153 - accuracy: 0.8206\n",
      "Epoch 21/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.5876 - accuracy: 0.8284\n",
      "Epoch 22/100\n",
      "571/571 [==============================] - 65s 114ms/step - loss: 0.6128 - accuracy: 0.8211\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 64s 113ms/step - loss: 0.5894 - accuracy: 0.8273\n",
      "Epoch 00023: early stopping\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (32, 2000, 128)           3968      \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (32, 32)                  18560     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 15)                  495       \n",
      "=================================================================\n",
      "Total params: 23,023\n",
      "Trainable params: 23,023\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "81.78125023841858\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (32, 2000, 128)           3968      \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (32, 32)                  18560     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 15)                  495       \n",
      "=================================================================\n",
      "Total params: 23,023\n",
      "Trainable params: 23,023\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 1.6088 - accuracy: 0.5186\n",
      "Epoch 2/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 1.1165 - accuracy: 0.6715\n",
      "Epoch 3/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.9559 - accuracy: 0.7181\n",
      "Epoch 4/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.8994 - accuracy: 0.7363\n",
      "Epoch 5/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.8332 - accuracy: 0.7630\n",
      "Epoch 6/100\n",
      "571/571 [==============================] - 65s 113ms/step - loss: 0.8948 - accuracy: 0.7400\n",
      "Epoch 7/100\n",
      "571/571 [==============================] - 65s 113ms/step - loss: 0.8104 - accuracy: 0.7678\n",
      "Epoch 8/100\n",
      "571/571 [==============================] - 65s 113ms/step - loss: 0.7571 - accuracy: 0.7819\n",
      "Epoch 9/100\n",
      "571/571 [==============================] - 65s 113ms/step - loss: 0.7238 - accuracy: 0.7883\n",
      "Epoch 10/100\n",
      "571/571 [==============================] - 65s 113ms/step - loss: 0.6792 - accuracy: 0.8065\n",
      "Epoch 11/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.7191 - accuracy: 0.7884\n",
      "Epoch 12/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.6761 - accuracy: 0.8014\n",
      "Epoch 13/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.6928 - accuracy: 0.7938\n",
      "Epoch 14/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.6452 - accuracy: 0.8126\n",
      "Epoch 15/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.6208 - accuracy: 0.8197\n",
      "Epoch 16/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.6130 - accuracy: 0.8225\n",
      "Epoch 17/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.6098 - accuracy: 0.8208\n",
      "Epoch 18/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.5990 - accuracy: 0.8242\n",
      "Epoch 19/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.5708 - accuracy: 0.8337\n",
      "Epoch 20/100\n",
      "571/571 [==============================] - 64s 113ms/step - loss: 0.5646 - accuracy: 0.8364\n",
      "Epoch 21/100\n",
      "571/571 [==============================] - 65s 114ms/step - loss: 0.5558 - accuracy: 0.8355\n",
      "Epoch 22/100\n",
      "571/571 [==============================] - 65s 114ms/step - loss: 0.5291 - accuracy: 0.8447\n",
      "Epoch 23/100\n",
      "571/571 [==============================] - 65s 114ms/step - loss: 0.5418 - accuracy: 0.8410\n",
      "Epoch 24/100\n",
      "571/571 [==============================] - 65s 114ms/step - loss: 0.5569 - accuracy: 0.8365\n",
      "Epoch 00024: early stopping\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (32, 2000, 128)           3968      \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (32, 32)                  18560     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 15)                  495       \n",
      "=================================================================\n",
      "Total params: 23,023\n",
      "Trainable params: 23,023\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "83.21874737739563\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (32, 2000, 128)           3968      \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (32, 32)                  18560     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 15)                  495       \n",
      "=================================================================\n",
      "Total params: 23,023\n",
      "Trainable params: 23,023\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "571/571 [==============================] - 66s 116ms/step - loss: 1.6248 - accuracy: 0.5350\n",
      "Epoch 2/100\n",
      " 32/571 [>.............................] - ETA: 59s - loss: 1.3042 - accuracy: 0.6602"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-cfe4f053d403>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mmodel_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     history = model_train.fit(x=train_data,\n\u001b[0m\u001b[0;32m     13\u001b[0m                           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "model_train = \"\"\n",
    "\n",
    "for i in range(10):\n",
    "    # get train and test data\n",
    "    train_data, test_data, train_labels, test_labels = split_data(train_data_raw, train_labels_raw)\n",
    "    \n",
    "    # train model\n",
    "    model_train = create_model()\n",
    "    early_stopping = EarlyStopping(monitor='loss', verbose=1, patience=2)\n",
    "    history = model_train.fit(x=train_data,\n",
    "                          y=train_labels,\n",
    "                          batch_size=batch_size,\n",
    "                          callbacks = [early_stopping],\n",
    "                          epochs=num_epochs,)\n",
    "    \n",
    "    # evaluate\n",
    "    model_evaluate = create_model()\n",
    "    model_evaluate.set_weights(model_train.get_weights())\n",
    "\n",
    "    scores = model_evaluate.evaluate(test_data, test_labels, verbose=0, callbacks = [early_stopping])\n",
    "    accuracy = scores[1]*100\n",
    "    print(accuracy)\n",
    "    results.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import win32api\n",
    "\n",
    "for x in results:\n",
    "    print(x)\n",
    "    \n",
    "win32api.MessageBox(0, 'hello', 'title', 0x00001000) \n",
    "\n",
    "model_train.save_weights(saved_model_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use History to plot and accuracy throughout training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, 2000, 128)           3968      \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (64, 128)                 98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, 5)                   645       \n",
      "=================================================================\n",
      "Total params: 103,429\n",
      "Trainable params: 103,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (64, 2000) for input Tensor(\"input_7:0\", shape=(64, 2000), dtype=float32), but it was called on an input with incompatible shape (32, 2000).\n",
      "WARNING:tensorflow:Model was constructed with shape (64, 2000) for input Tensor(\"input_7:0\", shape=(64, 2000), dtype=float32), but it was called on an input with incompatible shape (32, 2000).\n",
      "Accuracy: 89.69%\n"
     ]
    }
   ],
   "source": [
    "model_evaluate = create_model()\n",
    "model_evaluate.set_weights(model_train.get_weights())\n",
    "\n",
    "scores = model_evaluate.evaluate(test_set, test_labels, verbose=0, callbacks=[callback])\n",
    "accuracy = scores[1]*100\n",
    "print(\"Accuracy: %0.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model From Save and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.load_weights(saved_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_set, test_labels, verbose=0)\n",
    "accuracy = scores[1]*100\n",
    "print(\"Accuracy: %0.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate winwebsec and zbot test data\n",
    "winwebsec_test_data = []\n",
    "zbot_test_data = []\n",
    "\n",
    "for i in range(len(test_labels)):\n",
    "    if test_labels[i] == 0:\n",
    "        winwebsec_test_data.append(test_set[i])\n",
    "    else:\n",
    "        zbot_test_data.append(test_set[i])\n",
    "        \n",
    "winwebsec_test_data = np.asarray(winwebsec_test_data[:192])\n",
    "zbot_test_data = np.asarray(zbot_test_data[:128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(winwebsec_test_data.shape)\n",
    "print(zbot_test_data.shape)\n",
    "\n",
    "\n",
    "winwebsecY = model.predict(winwebsec_test_data)\n",
    "winwebsecX = [i+1 for i in range(len(winwebsec_test_data))]\n",
    "\n",
    "zbotY = model.predict(zbot_test_data)\n",
    "zbotX = [i+1 for i in range(len(zbot_test_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(100)\n",
    "f = plt.scatter(winwebsecX, winwebsecY, marker='o',\n",
    "                c='darkblue', s=30, label=\"winwebsec\")\n",
    "plt.scatter(zbotX, zbotY, marker='o', c='red', s=30, label=\"zbot\")\n",
    "plt.title(\"Winwebsec vs. Zbot LSTM Prediction Scatter Plot\",\n",
    "          fontsize=18, wrap=True)\n",
    "f.axes.get_xaxis().set_visible(False)\n",
    "plt.ylabel(\"Prediction\", fontsize=15)\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortByFirstItem(item):\n",
    "    return item[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winwebsecROC = [(data, \"winwebsec\") for data in winwebsecY]\n",
    "zbotROC = [(data, \"zbot\") for data in zbotY]\n",
    "\n",
    "zbotROC.sort(key=sortByFirstItem)\n",
    "winwebsecROC.sort(key=sortByFirstItem)\n",
    "\n",
    "dataROC = zbotROC + winwebsecROC\n",
    "dataROC.sort(key=sortByFirstItem, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_TPR_FPR(thresholdLine, dataROC):\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "\n",
    "    for data in dataROC:\n",
    "        yVal = data[0]\n",
    "        family = data[1]\n",
    "\n",
    "        if family == \"winwebsec\":\n",
    "            if yVal < thresholdLine:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        elif family == \"zbot\":\n",
    "            if yVal > thresholdLine:\n",
    "                TN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "    TPR = TP/(TP+FN)\n",
    "    FPR = 1 - (TN/(TN+FP))\n",
    "\n",
    "    return TPR, FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAUC(rocData):\n",
    "    sum = 0\n",
    "\n",
    "    # initialization\n",
    "    prevX = -1\n",
    "    prevY = -1\n",
    "\n",
    "    for points in rocData:\n",
    "        curX = points[0]\n",
    "        curY = points[1]\n",
    "\n",
    "        # Skip for first point\n",
    "        if prevX != -1 and prevY != -1:\n",
    "            # check if rectangle\n",
    "            if prevY == curY:\n",
    "                sum += abs(curX - prevX) * prevY\n",
    "            # check if trapezoid\n",
    "            else:\n",
    "                sum += (curY + prevY) * abs(curX - prevX) * 0.5\n",
    "\n",
    "        prevX = curX\n",
    "        prevY = curY\n",
    "\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocX = list()  # used to plot\n",
    "rocY = list()  # used to plot\n",
    "rocData = list()    # used to calculate AUC\n",
    "\n",
    "for entry in dataROC:\n",
    "    thresholdLine = entry[0]\n",
    "    TPR, FPR = calculate_TPR_FPR(thresholdLine, dataROC)\n",
    "\n",
    "    rocX.append(FPR)\n",
    "    rocY.append(TPR)\n",
    "    rocData.append([FPR, TPR])\n",
    "\n",
    "rocData.sort(key=lambda item: (item[0], item[1]), reverse=True)\n",
    "\n",
    "AUC = round(calculateAUC(rocData), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "\n",
    "plt.figure(200)\n",
    "plt.plot(rocX, rocY, marker=\".\", markersize=8)\n",
    "plt.title(\"Winwebsec vs. Zbot LSTM Log Probability ROC\", fontsize=18)\n",
    "plt.xlabel(\"FPR\", fontsize=15)\n",
    "plt.ylabel(\"TPR\", fontsize=15)\n",
    "plt.grid()\n",
    "plt.text(x=0.75, y=0, s=\"AUC: {0}\".format(AUC), fontsize=14, bbox=props)\n",
    "\n",
    "# show plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shutdown:\n",
    "    os.system('shutdown -s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
