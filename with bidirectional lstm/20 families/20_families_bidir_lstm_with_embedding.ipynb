{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '..\\\\..\\\\')\n",
    "\n",
    "import os\n",
    "import data_loader\n",
    "from numpy import trapz\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import win32api\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Dropout, Embedding, Bidirectional, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "malware_data_dir = '../../data/'\n",
    "saved_model_path = 'saved_model/'\n",
    "# opcode_to_int_path = \"opcodeToInt.txt\"\n",
    "results_path = \"results.txt\"\n",
    "num_unique_opcodes = 30\n",
    "max_opcode_sequence_length = 2000\n",
    "embed_vector_length = 128\n",
    "num_lstm_unit = 16\n",
    "dropout_amt = 0.3\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "test_size= 0.15       # reserve for testing\n",
    "# num_families_to_use = 20\n",
    "\n",
    "shutdown = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " def split_data(train_data_raw, train_labels_raw):\n",
    "    # Split into training and testing data\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(train_data_raw, train_labels_raw, test_size=test_size)\n",
    "\n",
    "    # Make divisible by batch size\n",
    "    num_data_train = int(len(train_data)/batch_size) * batch_size\n",
    "    num_data_test = int(len(test_data)/batch_size) * batch_size\n",
    "\n",
    "    train_data = train_data[:num_data_train]\n",
    "    train_labels = train_labels[:num_data_train]\n",
    "    test_data = test_data[:num_data_test]\n",
    "    test_labels = test_labels[:num_data_test]\n",
    "\n",
    "#     print(\"train_data shape: {}\".format(train_data.shape))\n",
    "#     print(\"test_data shape: {}\".format(test_data.shape))\n",
    "#     print(\"train_labels shape: {}\".format(train_labels.shape))\n",
    "#     print(\"test_labels shape: {}\".format(test_labels.shape))\n",
    "\n",
    "    return train_data, test_data, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_families_to_use):\n",
    "    model = Sequential()\n",
    "    model.add(Input(batch_shape=(batch_size, max_opcode_sequence_length), name=\"input\"))\n",
    "    model.add(Embedding(input_dim=num_unique_opcodes+1,\n",
    "                        output_dim=embed_vector_length,\n",
    "                        input_length=max_opcode_sequence_length, name=\"embedding\"))\n",
    "    model.add(Dropout(dropout_amt, name=\"dropout1\"))\n",
    "    model.add(Bidirectional(LSTM(num_lstm_unit), input_shape=(None, max_opcode_sequence_length)))\n",
    "    model.add(Dropout(dropout_amt, name=\"dropout2\"))\n",
    "    model.add(Dense(num_families_to_use, activation='softmax', name=\"dense\"))\n",
    "    optimizer = Adam()\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model():\n",
    "    num_families_to_use_list = [20]\n",
    "    results = {}\n",
    "    \n",
    "    for num_families_to_use in num_families_to_use_list:\n",
    "        print(\"{0} families....\".format(num_families_to_use))\n",
    "        \n",
    "        with open(results_path, 'a') as file:\n",
    "            file.write(str(num_families_to_use) + \"\\n\")\n",
    "            \n",
    "        opcode_to_int_path = \"opcodeToInt_\" + str(num_families_to_use) + \".txt\"\n",
    "        # Get train data\n",
    "        raw_train_data = data_loader.getTrainData(malware_data_dir, \n",
    "                                                  num_families_to_use, \n",
    "                                                  num_unique_opcodes, \n",
    "                                                  max_opcode_sequence_length, \n",
    "                                                  opcode_to_int_path)\n",
    "        # Data preprocessing\n",
    "        family_names = list(raw_train_data.keys())\n",
    "        print(family_names)\n",
    "\n",
    "        # Split opcode family data in individual lists\n",
    "        train_data = list()\n",
    "        for family, data in raw_train_data.items():\n",
    "            train_data.append(data)\n",
    "\n",
    "        # Pad training data to ensure uniformity\n",
    "        padded_train_data = list()\n",
    "        for family_opcodes in train_data:\n",
    "            padded_sequence = pad_sequences(family_opcodes, \n",
    "                                            maxlen=max_opcode_sequence_length)\n",
    "            padded_train_data.append(padded_sequence)\n",
    "\n",
    "        # Concatenate all training data into 1 long list instead of multiple lists\n",
    "        train_data_raw = np.concatenate(padded_train_data)\n",
    "\n",
    "        print(len(train_data))\n",
    "        \n",
    "        # Make labels\n",
    "        train_labels = []\n",
    "        for count, data in enumerate(padded_train_data):\n",
    "            labels_list = np.full(shape=(len(data)), fill_value=count)\n",
    "            train_labels.append(labels_list)\n",
    "\n",
    "        train_labels_raw = np.concatenate(train_labels)\n",
    "        \n",
    "        train_data_raw = train_data_raw.reshape(len(train_data_raw), max_opcode_sequence_length, 1)\n",
    "        train_labels_raw = train_labels_raw.reshape(len(train_data_raw), 1, 1)\n",
    "        \n",
    "        for i in range(1):\n",
    "            # get train and test data\n",
    "            train_data, test_data, train_labels, test_labels = split_data(train_data_raw, train_labels_raw)\n",
    "\n",
    "            # train model\n",
    "            model_train = create_model(num_families_to_use)\n",
    "            early_stopping = EarlyStopping(monitor='loss', \n",
    "                                           verbose=1, \n",
    "                                           patience=2,\n",
    "                                           restore_best_weights=True,\n",
    "                                           min_delta=0.03)\n",
    "            history = model_train.fit(x=train_data,\n",
    "                                      y=train_labels,\n",
    "                                      batch_size=batch_size,\n",
    "                                      callbacks = [early_stopping],\n",
    "                                      epochs=num_epochs,\n",
    "                                      shuffle=True)\n",
    "            \n",
    "            model_train.save_weights(saved_model_path) \n",
    "\n",
    "            # evaluate\n",
    "            model_evaluate = create_model(num_families_to_use)\n",
    "            model_evaluate.set_weights(model_train.get_weights())\n",
    "\n",
    "            scores = model_evaluate.evaluate(test_data, test_labels, verbose=0, callbacks = [early_stopping])\n",
    "            accuracy = scores[1]*100\n",
    "            print(\"{0}: {1}\".format(num_families_to_use, accuracy))\n",
    "            results[num_families_to_use] = accuracy\n",
    "\n",
    "#             with open(results_path, 'a') as file:\n",
    "#                 file.write(str(accuracy) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-04836f87c280>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model_train.fit(x=train_data,\n\u001b[0m\u001b[0;32m      2\u001b[0m                           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                           \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_train' is not defined"
     ]
    }
   ],
   "source": [
    "history = model_train.fit(x=train_data,\n",
    "                          y=train_labels,\n",
    "                          batch_size=batch_size,\n",
    "                          callbacks = [early_stopping],\n",
    "                          epochs=num_epochs,\n",
    "                          shuffle=True)\n",
    "\n",
    "model_train.save_weights(saved_model_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 families....\n",
      "Getting list of paths to training data\n",
      "{'winwebsec': 6862260, 'vundo': 3492760, 'zbot': 3256944, 'hotbar': 2952000, 'renos': 2612858, 'onlinegames': 2554166, 'obfuscator': 2502965, 'bho': 2315982, 'alureon': 2287866, 'zeroaccess': 2238000, 'delfinject': 2167855, 'startpage': 2164599, 'adload': 2088000, 'fakerean': 2082110, 'cycbot': 2058000, 'vobfus': 1848000, 'lolyda': 1830000, 'ceeinject': 1725371, 'agent': 1625496, 'rbot': 1623452}\n",
      "Loading training data for hotbar\n",
      "1476\n",
      "Loading training data for renos\n",
      "1309\n",
      "Loading training data for vundo\n",
      "1784\n",
      "Loading training data for winwebsec\n",
      "3651\n",
      "Loading training data for zbot\n",
      "1785\n",
      "Loading training data for alureon\n",
      "1325\n",
      "Loading training data for bho\n",
      "1159\n",
      "Loading training data for obfuscator\n",
      "1310\n",
      "Loading training data for onlinegames\n",
      "1284\n",
      "Loading training data for zeroaccess\n",
      "1119\n",
      "Loading training data for adload\n",
      "1044\n",
      "Loading training data for cycbot\n",
      "1029\n",
      "Loading training data for delfinject\n",
      "1090\n",
      "Loading training data for fakerean\n",
      "1063\n",
      "Loading training data for startpage\n",
      "1084\n",
      "Loading training data for agent\n",
      "817\n",
      "Loading training data for ceeinject\n",
      "886\n",
      "Loading training data for lolyda\n",
      "915\n",
      "Loading training data for rbot\n",
      "817\n",
      "Loading training data for vobfus\n",
      "924\n",
      "All training data loaded\n",
      "total opcodes counted: 50312882\n",
      "total covered: 40670869\n",
      "total not covered: 9642013\n",
      "0.8083589606335809\n",
      "['hotbar', 'renos', 'vundo', 'winwebsec', 'zbot', 'alureon', 'bho', 'obfuscator', 'onlinegames', 'zeroaccess', 'adload', 'cycbot', 'delfinject', 'fakerean', 'startpage', 'agent', 'ceeinject', 'lolyda', 'rbot', 'vobfus']\n",
      "20\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (32, 2000, 128)           3968      \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (32, 2000, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (32, 32)                  18560     \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (32, 32)                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 20)                  660       \n",
      "=================================================================\n",
      "Total params: 23,188\n",
      "Trainable params: 23,188\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "687/687 [==============================] - 79s 116ms/step - loss: 2.0882 - accuracy: 0.4183\n",
      "Epoch 2/100\n",
      "687/687 [==============================] - 79s 115ms/step - loss: 1.5734 - accuracy: 0.5575\n",
      "Epoch 3/100\n",
      "687/687 [==============================] - 79s 115ms/step - loss: 1.4324 - accuracy: 0.5971\n",
      "Epoch 4/100\n",
      "687/687 [==============================] - 81s 118ms/step - loss: 1.3309 - accuracy: 0.6235\n",
      "Epoch 5/100\n",
      "687/687 [==============================] - 80s 117ms/step - loss: 1.3656 - accuracy: 0.6159\n",
      "Epoch 6/100\n",
      "687/687 [==============================] - 79s 115ms/step - loss: 1.2505 - accuracy: 0.6475\n",
      "Epoch 7/100\n",
      "687/687 [==============================] - 79s 115ms/step - loss: 1.1942 - accuracy: 0.6613\n",
      "Epoch 8/100\n",
      "687/687 [==============================] - 79s 115ms/step - loss: 1.1487 - accuracy: 0.6739\n",
      "Epoch 9/100\n",
      "687/687 [==============================] - 79s 115ms/step - loss: 1.1832 - accuracy: 0.6620\n",
      "Epoch 10/100\n",
      "687/687 [==============================] - ETA: 0s - loss: 1.1355 - accuracy: 0.6778Restoring model weights from the end of the best epoch.\n",
      "687/687 [==============================] - 80s 116ms/step - loss: 1.1355 - accuracy: 0.6778\n",
      "Epoch 00010: early stopping\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (32, 2000, 128)           3968      \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (32, 2000, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (32, 32)                  18560     \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (32, 32)                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 20)                  660       \n",
      "=================================================================\n",
      "Total params: 23,188\n",
      "Trainable params: 23,188\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "20: 71.56507968902588\n"
     ]
    }
   ],
   "source": [
    "run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (32, 2000, 128)           3968      \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (32, 2000, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (32, 32)                  18560     \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (32, 32)                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 20)                  660       \n",
      "=================================================================\n",
      "Total params: 23,188\n",
      "Trainable params: 23,188\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-0ff910b07663>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel_evaluate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaved_model_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_evaluate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0}: {1}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_families_to_use\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "model_evaluate = create_model(20)\n",
    "model_evaluate.load_weights(saved_model_path)\n",
    "\n",
    "scores = model_evaluate.evaluate(test_data, test_labels, verbose=0, callbacks = [early_stopping])\n",
    "accuracy = scores[1]*100\n",
    "print(\"{0}: {1}\".format(num_families_to_use, accuracy))\n",
    "results[num_families_to_use] = accuracy\n",
    "\n",
    "#             with open(results_path, 'a') as file:\n",
    "#                 file.write(str(accuracy) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-77f62f33175a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions_train_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_evaluate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpredictions_test_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_evaluate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlabels_train_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlabels_test_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "predictions_train_set = model_evaluate.predict_classes(train_data, verbose=1)\n",
    "predictions_test_set = model_evaluate.predict_classes(test_data, verbose=1)\n",
    "labels_train_set = train_labels.reshape((-1))\n",
    "labels_test_set = test_labels.reshape((-1))\n",
    "\n",
    "predictions = np.concatenate((predictions_train_set, predictions_test_set))\n",
    "labels = np.concatenate((labels_train_set, labels_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi'] = 300\n",
    "matrix = confusion_matrix(y_true=labels,\n",
    "                            y_pred=predictions)\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=matrix,\n",
    "                                show_absolute=False,\n",
    "                                show_normed=True,\n",
    "                                class_names=family_names,\n",
    "                                figsize=(12,12))\n",
    "\n",
    "for item in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(10)\n",
    "\n",
    "\n",
    "ax.set_title(\"Confusion Matrix for LSTM Model With Embedding and BiLSTM\", fontsize=15, fontweight='bold')\n",
    "ax.set_ylabel(\"True Family\", fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel(\"Predicted Family\", fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('shutdown -s -t 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_train_data = data_loader.getTrainData(malware_data_dir, \n",
    "                                          num_families_to_use, \n",
    "                                          num_unique_opcodes, \n",
    "                                          max_opcode_sequence_length, \n",
    "                                          opcode_to_int_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_names = list(raw_train_data.keys())\n",
    "print(family_names)\n",
    "\n",
    "# Split opcode family data in individual lists\n",
    "train_data = list()\n",
    "for family, data in raw_train_data.items():\n",
    "    train_data.append(data)\n",
    "    \n",
    "# Pad training data to ensure uniformity\n",
    "padded_train_data = list()\n",
    "for family_opcodes in train_data:\n",
    "    padded_sequence = pad_sequences(family_opcodes, \n",
    "                                    maxlen=max_opcode_sequence_length)\n",
    "    padded_train_data.append(padded_sequence)\n",
    "    \n",
    "# Concatenate all training data into 1 long list instead of multiple lists\n",
    "train_data_raw = np.concatenate(padded_train_data)\n",
    "\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "\n",
    "for count, data in enumerate(padded_train_data):\n",
    "    labels_list = np.full(shape=(len(data)), fill_value=count)\n",
    "    train_labels.append(labels_list)\n",
    "\n",
    "train_labels_raw = np.concatenate(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(train_data_raw, train_labels_raw):\n",
    "    # Split into training and testing data\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(train_data_raw, train_labels_raw, test_size=test_size)\n",
    "\n",
    "    # Make divisible by batch size\n",
    "    num_data_train = int(len(train_data)/batch_size) * batch_size\n",
    "    num_data_test = int(len(test_data)/batch_size) * batch_size\n",
    "\n",
    "    train_data = train_data[:num_data_train]\n",
    "    train_labels = train_labels[:num_data_train]\n",
    "    test_data = test_data[:num_data_test]\n",
    "    test_labels = test_labels[:num_data_test]\n",
    "    \n",
    "    print(\"train_data shape: {}\".format(train_data.shape))\n",
    "    print(\"test_data shape: {}\".format(test_data.shape))\n",
    "    print(\"train_labels shape: {}\".format(train_labels.shape))\n",
    "    print(\"test_labels shape: {}\".format(test_labels.shape))\n",
    "    \n",
    "    return train_data, test_data, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Input(batch_shape=(batch_size, max_opcode_sequence_length), name=\"input\"))\n",
    "    model.add(Embedding(input_dim=num_unique_opcodes+1,\n",
    "                        output_dim=embed_vector_length,\n",
    "                        input_length=max_opcode_sequence_length, name=\"embedding\"))\n",
    "    model.add(Dropout(dropout_amt, name=\"dropout1\"))\n",
    "    model.add(Conv1D(filters=embed_vector_length, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(Dropout(dropout_amt, name=\"dropout2\"))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_amt, name=\"dropout3\"))\n",
    "    model.add(Bidirectional(LSTM(num_lstm_unit), input_shape=(None, max_opcode_sequence_length)))\n",
    "    model.add(Dropout(dropout_amt, name=\"dropout4\"))\n",
    "    model.add(Dense(num_families_to_use, activation='softmax', name=\"dense\"))\n",
    "    optimizer = Adam()\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(4):\n",
    "    # get train and test data\n",
    "    train_data, test_data, train_labels, test_labels = split_data(train_data_raw, train_labels_raw)\n",
    "    \n",
    "    # train model\n",
    "    model_train = create_model()\n",
    "    early_stopping = EarlyStopping(monitor='loss', \n",
    "                                   verbose=1, \n",
    "                                   patience=2,\n",
    "                                   restore_best_weights=True,\n",
    "                                   min_delta=0.001)\n",
    "    history = model_train.fit(x=train_data,\n",
    "                              y=train_labels,\n",
    "                              batch_size=batch_size,\n",
    "                              callbacks = [early_stopping],\n",
    "                              epochs=num_epochs,\n",
    "                              shuffle=True)\n",
    "    \n",
    "    # evaluate\n",
    "    model_evaluate = create_model()\n",
    "    model_evaluate.set_weights(model_train.get_weights())\n",
    "\n",
    "    scores = model_evaluate.evaluate(test_data, test_labels, verbose=0, callbacks = [early_stopping])\n",
    "    accuracy = scores[1]*100\n",
    "    print(accuracy)\n",
    "    results.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in results:\n",
    "    print(x)\n",
    "    \n",
    "win32api.MessageBox(0, 'done', 'title', 0x00001000) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use History to plot and accuracy throughout training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluate = create_model()\n",
    "model_evaluate.set_weights(model_train.get_weights())\n",
    "\n",
    "scores = model_evaluate.evaluate(test_set, test_labels, verbose=0, callbacks=[callback])\n",
    "accuracy = scores[1]*100\n",
    "print(\"Accuracy: %0.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model From Save and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.load_weights(saved_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_set, test_labels, verbose=0)\n",
    "accuracy = scores[1]*100\n",
    "print(\"Accuracy: %0.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate winwebsec and zbot test data\n",
    "winwebsec_test_data = []\n",
    "zbot_test_data = []\n",
    "\n",
    "for i in range(len(test_labels)):\n",
    "    if test_labels[i] == 0:\n",
    "        winwebsec_test_data.append(test_set[i])\n",
    "    else:\n",
    "        zbot_test_data.append(test_set[i])\n",
    "        \n",
    "winwebsec_test_data = np.asarray(winwebsec_test_data[:192])\n",
    "zbot_test_data = np.asarray(zbot_test_data[:128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(winwebsec_test_data.shape)\n",
    "print(zbot_test_data.shape)\n",
    "\n",
    "\n",
    "winwebsecY = model.predict(winwebsec_test_data)\n",
    "winwebsecX = [i+1 for i in range(len(winwebsec_test_data))]\n",
    "\n",
    "zbotY = model.predict(zbot_test_data)\n",
    "zbotX = [i+1 for i in range(len(zbot_test_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(100)\n",
    "f = plt.scatter(winwebsecX, winwebsecY, marker='o',\n",
    "                c='darkblue', s=30, label=\"winwebsec\")\n",
    "plt.scatter(zbotX, zbotY, marker='o', c='red', s=30, label=\"zbot\")\n",
    "plt.title(\"Winwebsec vs. Zbot LSTM Prediction Scatter Plot\",\n",
    "          fontsize=18, wrap=True)\n",
    "f.axes.get_xaxis().set_visible(False)\n",
    "plt.ylabel(\"Prediction\", fontsize=15)\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortByFirstItem(item):\n",
    "    return item[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winwebsecROC = [(data, \"winwebsec\") for data in winwebsecY]\n",
    "zbotROC = [(data, \"zbot\") for data in zbotY]\n",
    "\n",
    "zbotROC.sort(key=sortByFirstItem)\n",
    "winwebsecROC.sort(key=sortByFirstItem)\n",
    "\n",
    "dataROC = zbotROC + winwebsecROC\n",
    "dataROC.sort(key=sortByFirstItem, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_TPR_FPR(thresholdLine, dataROC):\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "\n",
    "    for data in dataROC:\n",
    "        yVal = data[0]\n",
    "        family = data[1]\n",
    "\n",
    "        if family == \"winwebsec\":\n",
    "            if yVal < thresholdLine:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        elif family == \"zbot\":\n",
    "            if yVal > thresholdLine:\n",
    "                TN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "    TPR = TP/(TP+FN)\n",
    "    FPR = 1 - (TN/(TN+FP))\n",
    "\n",
    "    return TPR, FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAUC(rocData):\n",
    "    sum = 0\n",
    "\n",
    "    # initialization\n",
    "    prevX = -1\n",
    "    prevY = -1\n",
    "\n",
    "    for points in rocData:\n",
    "        curX = points[0]\n",
    "        curY = points[1]\n",
    "\n",
    "        # Skip for first point\n",
    "        if prevX != -1 and prevY != -1:\n",
    "            # check if rectangle\n",
    "            if prevY == curY:\n",
    "                sum += abs(curX - prevX) * prevY\n",
    "            # check if trapezoid\n",
    "            else:\n",
    "                sum += (curY + prevY) * abs(curX - prevX) * 0.5\n",
    "\n",
    "        prevX = curX\n",
    "        prevY = curY\n",
    "\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocX = list()  # used to plot\n",
    "rocY = list()  # used to plot\n",
    "rocData = list()    # used to calculate AUC\n",
    "\n",
    "for entry in dataROC:\n",
    "    thresholdLine = entry[0]\n",
    "    TPR, FPR = calculate_TPR_FPR(thresholdLine, dataROC)\n",
    "\n",
    "    rocX.append(FPR)\n",
    "    rocY.append(TPR)\n",
    "    rocData.append([FPR, TPR])\n",
    "\n",
    "rocData.sort(key=lambda item: (item[0], item[1]), reverse=True)\n",
    "\n",
    "AUC = round(calculateAUC(rocData), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "\n",
    "plt.figure(200)\n",
    "plt.plot(rocX, rocY, marker=\".\", markersize=8)\n",
    "plt.title(\"Winwebsec vs. Zbot LSTM Log Probability ROC\", fontsize=18)\n",
    "plt.xlabel(\"FPR\", fontsize=15)\n",
    "plt.ylabel(\"TPR\", fontsize=15)\n",
    "plt.grid()\n",
    "plt.text(x=0.75, y=0, s=\"AUC: {0}\".format(AUC), fontsize=14, bbox=props)\n",
    "\n",
    "# show plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shutdown:\n",
    "    os.system('shutdown -s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
