{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '..\\\\..\\\\')\n",
    "\n",
    "import os\n",
    "import data_loader\n",
    "from numpy import trapz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "malware_data_dir = '../../data/'\n",
    "saved_model_path = 'saved_model/'\n",
    "#opcode_to_int_path = \"opcodeToInt.txt\"\n",
    "num_unique_opcodes = 30\n",
    "max_opcode_sequence_length = 2000\n",
    "embed_vector_length = 128\n",
    "num_lstm_unit = 16\n",
    "dropout_amt = 0.3\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "test_size= 0.15       # reserve for testing\n",
    "results_path = \"results.txt\"\n",
    "#num_families_to_use = 20\n",
    "\n",
    "shutdown = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " def split_data(train_data_raw, train_labels_raw):\n",
    "    # Split into training and testing data\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(train_data_raw, train_labels_raw, test_size=test_size)\n",
    "\n",
    "    # Make divisible by batch size\n",
    "    num_data_train = int(len(train_data)/batch_size) * batch_size\n",
    "    num_data_test = int(len(test_data)/batch_size) * batch_size\n",
    "\n",
    "    train_data = train_data[:num_data_train]\n",
    "    train_labels = train_labels[:num_data_train]\n",
    "    test_data = test_data[:num_data_test]\n",
    "    test_labels = test_labels[:num_data_test]\n",
    "\n",
    "#     print(\"train_data shape: {}\".format(train_data.shape))\n",
    "#     print(\"test_data shape: {}\".format(test_data.shape))\n",
    "#     print(\"train_labels shape: {}\".format(train_labels.shape))\n",
    "#     print(\"test_labels shape: {}\".format(test_labels.shape))\n",
    "\n",
    "    return train_data, test_data, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_families_to_use):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=num_lstm_unit, \n",
    "                   input_shape=(max_opcode_sequence_length, 1),\n",
    "                   name=\"lstm1\"))\n",
    "    model.add(Dropout(dropout_amt))\n",
    "    model.add(Dense(units=num_families_to_use, activation='softmax', name=\"dense\"))\n",
    "    optimizer = Adam()\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_families_to_use_list = [20]\n",
    "results = {}\n",
    "\n",
    "for num_families_to_use in num_families_to_use_list:\n",
    "    print(\"{0} families....\".format(num_families_to_use))\n",
    "\n",
    "    with open(results_path, 'a') as file:\n",
    "        file.write(str(num_families_to_use) + \"\\n\")\n",
    "\n",
    "    opcode_to_int_path = \"opcodeToInt_\" + str(num_families_to_use) + \".txt\"\n",
    "    # Get train data\n",
    "    raw_train_data = data_loader.getTrainData(malware_data_dir, \n",
    "                                              num_families_to_use, \n",
    "                                              num_unique_opcodes, \n",
    "                                              max_opcode_sequence_length, \n",
    "                                              opcode_to_int_path)\n",
    "    # Data preprocessing\n",
    "    family_names = list(raw_train_data.keys())\n",
    "    print(family_names)\n",
    "\n",
    "    # Split opcode family data in individual lists\n",
    "    train_data = list()\n",
    "    for family, data in raw_train_data.items():\n",
    "        train_data.append(data)\n",
    "\n",
    "    # Pad training data to ensure uniformity\n",
    "    padded_train_data = list()\n",
    "    for family_opcodes in train_data:\n",
    "        padded_sequence = pad_sequences(family_opcodes, \n",
    "                                        maxlen=max_opcode_sequence_length)\n",
    "        padded_train_data.append(padded_sequence)\n",
    "\n",
    "    # Concatenate all training data into 1 long list instead of multiple lists\n",
    "    train_data_raw = np.concatenate(padded_train_data)\n",
    "\n",
    "    print(len(train_data))\n",
    "\n",
    "    # Make labels\n",
    "    train_labels = []\n",
    "    for count, data in enumerate(padded_train_data):\n",
    "        labels_list = np.full(shape=(len(data)), fill_value=count)\n",
    "        train_labels.append(labels_list)\n",
    "\n",
    "    train_labels_raw = np.concatenate(train_labels)\n",
    "\n",
    "    train_data_raw = train_data_raw.reshape(len(train_data_raw), max_opcode_sequence_length, 1)\n",
    "    train_labels_raw = train_labels_raw.reshape(len(train_data_raw), 1, 1)\n",
    "\n",
    "    # get train and test data\n",
    "    train_data, test_data, train_labels, test_labels = split_data(train_data_raw, train_labels_raw)\n",
    "\n",
    "    # train model\n",
    "    model_train = create_model(num_families_to_use)\n",
    "    early_stopping = EarlyStopping(monitor='loss', \n",
    "                                   verbose=1, \n",
    "                                   patience=2,\n",
    "                                   restore_best_weights=True,\n",
    "                                   min_delta=0.03)\n",
    "     prediction = model_train.predict(x=train_data_raw, \n",
    "                                      verbose=1, \n",
    "                                      callbacks=[early_stopping])\n",
    "    print(prediction)\n",
    "    \n",
    "#     history = model_train.fit(x=train_data,\n",
    "#                               y=train_labels,\n",
    "#                               batch_size=batch_size,\n",
    "#                               callbacks = [early_stopping],\n",
    "#                               epochs=num_epochs,\n",
    "#                               shuffle=True)\n",
    "#     model_train.save_weights(str(saved_model_path) + \"_\" + str(num_families_to_use)) \n",
    "\n",
    "#     # evaluate\n",
    "#     model_evaluate = create_model(num_families_to_use)\n",
    "#     model_evaluate.set_weights(model_train.get_weights())\n",
    "\n",
    "#     scores = model_evaluate.evaluate(test_data, test_labels, verbose=0, callbacks = [early_stopping])\n",
    "#     accuracy = scores[1]*100\n",
    "#     print(\"{0}: {1}\".format(num_families_to_use, accuracy))\n",
    "#     results[num_families_to_use] = accuracy\n",
    "\n",
    "#     with open(results_path, 'a') as file:\n",
    "#         file.write(str(accuracy) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 families....\n",
      "Getting list of paths to training data\n",
      "{'winwebsec': 6862260, 'vundo': 3492760, 'zbot': 3256944, 'hotbar': 2952000, 'renos': 2612858, 'onlinegames': 2554166, 'obfuscator': 2502965, 'bho': 2315982, 'alureon': 2287866, 'zeroaccess': 2238000, 'delfinject': 2167855, 'startpage': 2164599, 'adload': 2088000, 'fakerean': 2082110, 'cycbot': 2058000, 'vobfus': 1848000, 'lolyda': 1830000, 'ceeinject': 1725371, 'agent': 1625496, 'rbot': 1623452}\n",
      "Loading training data for hotbar\n",
      "Loading training data for renos\n",
      "Loading training data for vundo\n",
      "Loading training data for winwebsec\n",
      "Loading training data for zbot\n",
      "Loading training data for alureon\n",
      "Loading training data for bho\n",
      "Loading training data for obfuscator\n",
      "Loading training data for onlinegames\n",
      "Loading training data for zeroaccess\n",
      "Loading training data for adload\n",
      "Loading training data for cycbot\n",
      "Loading training data for delfinject\n",
      "Loading training data for fakerean\n",
      "Loading training data for startpage\n",
      "Loading training data for agent\n",
      "Loading training data for ceeinject\n",
      "Loading training data for lolyda\n",
      "Loading training data for rbot\n",
      "Loading training data for vobfus\n",
      "All training data loaded\n",
      "['hotbar', 'renos', 'vundo', 'winwebsec', 'zbot', 'alureon', 'bho', 'obfuscator', 'onlinegames', 'zeroaccess', 'adload', 'cycbot', 'delfinject', 'fakerean', 'startpage', 'agent', 'ceeinject', 'lolyda', 'rbot', 'vobfus']\n",
      "20\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm1 (LSTM)                 (None, 16)                1152      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                340       \n",
      "=================================================================\n",
      "Total params: 1,492\n",
      "Trainable params: 1,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "687/687 [==============================] - 35s 51ms/step - loss: 2.7588 - accuracy: 0.1710\n",
      "Epoch 2/100\n",
      "687/687 [==============================] - 35s 51ms/step - loss: 2.5790 - accuracy: 0.2124\n",
      "Epoch 3/100\n",
      "687/687 [==============================] - 35s 51ms/step - loss: 2.4781 - accuracy: 0.2462\n",
      "Epoch 4/100\n",
      "687/687 [==============================] - 35s 51ms/step - loss: 2.4390 - accuracy: 0.2587\n",
      "Epoch 5/100\n",
      "687/687 [==============================] - 35s 51ms/step - loss: 2.3923 - accuracy: 0.2699\n",
      "Epoch 6/100\n",
      "687/687 [==============================] - 35s 51ms/step - loss: 2.3615 - accuracy: 0.2796\n",
      "Epoch 7/100\n",
      "687/687 [==============================] - 35s 51ms/step - loss: 2.5171 - accuracy: 0.2440\n",
      "Epoch 8/100\n",
      "687/687 [==============================] - ETA: 0s - loss: 2.4289 - accuracy: 0.2539Restoring model weights from the end of the best epoch.\n",
      "687/687 [==============================] - 35s 51ms/step - loss: 2.4289 - accuracy: 0.2539\n",
      "Epoch 00008: early stopping\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm1 (LSTM)                 (None, 16)                1152      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                340       \n",
      "=================================================================\n",
      "Total params: 1,492\n",
      "Trainable params: 1,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "20: 29.209712147712708\n"
     ]
    }
   ],
   "source": [
    "run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "array = [[13,1,1,0,2,0],\n",
    "         [3,9,6,0,1,0],\n",
    "         [0,0,16,2,0,0],\n",
    "         [0,0,0,13,0,0],\n",
    "         [0,0,0,0,15,0],\n",
    "         [0,0,1,0,0,15]]\n",
    "\n",
    "df_cm = pd.DataFrame(array, range(6), range(6))\n",
    "# plt.figure(figsize=(10,7))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hotbar_training, renos_training, vundo_training, winwebsec_training, zbot_training = data_loader.getTrainData(all_files_dir, \n",
    "                                        keep_amt, \n",
    "                                        max_opcode_length, \n",
    "                                        opcode_to_int_path)\n",
    "\n",
    "# Pad data\n",
    "hotbar_training = pad_sequences(hotbar_training, maxlen=max_opcode_length)\n",
    "renos_training = pad_sequences(renos_training, maxlen=max_opcode_length)\n",
    "vundo_training = pad_sequences(vundo_training, maxlen=max_opcode_length)\n",
    "winwebsec_training = pad_sequences(winwebsec_training, maxlen=max_opcode_length)\n",
    "zbot_training = pad_sequences(zbot_training, maxlen=max_opcode_length)\n",
    "\n",
    "train_set = np.concatenate((hotbar_training, renos_training, vundo_training, winwebsec_training, zbot_training), axis=0)\n",
    "\n",
    "'''\n",
    "    Create labels:\n",
    "        0 - hotbar\n",
    "        1 - renos\n",
    "        2 - vundo\n",
    "        3 - winwebsec\n",
    "        4 - zbot\n",
    "'''\n",
    "hotbar_train_labels = np.zeros(shape=(len(hotbar_training), 1))\n",
    "renos_train_labels = np.ones(shape=(len(renos_training), 1))\n",
    "vundo_train_labels = np.full_like(renos_train_labels, 2)\n",
    "winwebsec_train_labels = np.full_like(renos_train_labels, 3)\n",
    "zbot_train_labels = np.full_like(renos_train_labels, 4)\n",
    "\n",
    "train_labels = np.concatenate((hotbar_train_labels, \n",
    "                               renos_train_labels, \n",
    "                               vundo_train_labels, \n",
    "                               winwebsec_train_labels,\n",
    "                               zbot_train_labels), axis=0)\n",
    "\n",
    "# Reshape matrices\n",
    "train_set = train_set.reshape(len(train_set), max_opcode_length, 1)\n",
    "train_labels = train_labels.reshape(len(train_set), 1, 1)\n",
    "\n",
    "# Split into training and testing data\n",
    "train_set, test_set, train_labels, test_labels = train_test_split(train_set, train_labels, test_size=test_size)\n",
    "\n",
    "print(\"train_set shape: {}\".format(train_set.shape))\n",
    "print(\"test_set shape: {}\".format(test_set.shape))\n",
    "print(\"train_labels shape: {}\".format(train_labels.shape))\n",
    "print(\"test_labels shape: {}\".format(test_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=num_lstm_unit, \n",
    "                   input_shape=(max_opcode_length, 1),\n",
    "                   return_sequences=True,\n",
    "                   name=\"lstm1\"))\n",
    "    model.add(Dropout(dropout_amt))\n",
    "    model.add(LSTM(units=num_lstm_unit*2,\n",
    "                   return_sequences=True,\n",
    "                   name=\"lstm2\"))\n",
    "    model.add(Dropout(dropout_amt))\n",
    "    model.add(LSTM(units=num_lstm_unit,\n",
    "                   name=\"lstm3\"))\n",
    "    model.add(Dense(units=5, activation='softmax', name=\"dense\"))\n",
    "    optimizer = Adam()\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=train_set,\n",
    "          y=train_labels,\n",
    "          batch_size=batch_size,\n",
    "          epochs=20,)\n",
    "\n",
    "model.save_weights(saved_model_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_set, test_labels, verbose=0, callbacks=[callback])\n",
    "accuracy = scores[1]*100\n",
    "print(\"Accuracy: %0.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model From Save and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.load_weights(saved_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_set, test_labels, verbose=0)\n",
    "accuracy = scores[1]*100\n",
    "print(\"Accuracy: %0.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate winwebsec and zbot test data\n",
    "winwebsec_test_data = []\n",
    "zbot_test_data = []\n",
    "\n",
    "for i in range(len(test_labels)):\n",
    "    if test_labels[i] == 0:\n",
    "        winwebsec_test_data.append(test_set[i])\n",
    "    else:\n",
    "        zbot_test_data.append(test_set[i])\n",
    "        \n",
    "winwebsec_test_data = np.asarray(winwebsec_test_data[:192])\n",
    "zbot_test_data = np.asarray(zbot_test_data[:128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(winwebsec_test_data.shape)\n",
    "print(zbot_test_data.shape)\n",
    "\n",
    "\n",
    "winwebsecY = model.predict(winwebsec_test_data)\n",
    "winwebsecX = [i+1 for i in range(len(winwebsec_test_data))]\n",
    "\n",
    "zbotY = model.predict(zbot_test_data)\n",
    "zbotX = [i+1 for i in range(len(zbot_test_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(100)\n",
    "f = plt.scatter(winwebsecX, winwebsecY, marker='o',\n",
    "                c='darkblue', s=30, label=\"winwebsec\")\n",
    "plt.scatter(zbotX, zbotY, marker='o', c='red', s=30, label=\"zbot\")\n",
    "plt.title(\"Winwebsec vs. Zbot LSTM Prediction Scatter Plot\",\n",
    "          fontsize=18, wrap=True)\n",
    "f.axes.get_xaxis().set_visible(False)\n",
    "plt.ylabel(\"Prediction\", fontsize=15)\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortByFirstItem(item):\n",
    "    return item[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winwebsecROC = [(data, \"winwebsec\") for data in winwebsecY]\n",
    "zbotROC = [(data, \"zbot\") for data in zbotY]\n",
    "\n",
    "zbotROC.sort(key=sortByFirstItem)\n",
    "winwebsecROC.sort(key=sortByFirstItem)\n",
    "\n",
    "dataROC = zbotROC + winwebsecROC\n",
    "dataROC.sort(key=sortByFirstItem, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_TPR_FPR(thresholdLine, dataROC):\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "\n",
    "    for data in dataROC:\n",
    "        yVal = data[0]\n",
    "        family = data[1]\n",
    "\n",
    "        if family == \"winwebsec\":\n",
    "            if yVal < thresholdLine:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        elif family == \"zbot\":\n",
    "            if yVal > thresholdLine:\n",
    "                TN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "    TPR = TP/(TP+FN)\n",
    "    FPR = 1 - (TN/(TN+FP))\n",
    "\n",
    "    return TPR, FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAUC(rocData):\n",
    "    sum = 0\n",
    "\n",
    "    # initialization\n",
    "    prevX = -1\n",
    "    prevY = -1\n",
    "\n",
    "    for points in rocData:\n",
    "        curX = points[0]\n",
    "        curY = points[1]\n",
    "\n",
    "        # Skip for first point\n",
    "        if prevX != -1 and prevY != -1:\n",
    "            # check if rectangle\n",
    "            if prevY == curY:\n",
    "                sum += abs(curX - prevX) * prevY\n",
    "            # check if trapezoid\n",
    "            else:\n",
    "                sum += (curY + prevY) * abs(curX - prevX) * 0.5\n",
    "\n",
    "        prevX = curX\n",
    "        prevY = curY\n",
    "\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocX = list()  # used to plot\n",
    "rocY = list()  # used to plot\n",
    "rocData = list()    # used to calculate AUC\n",
    "\n",
    "for entry in dataROC:\n",
    "    thresholdLine = entry[0]\n",
    "    TPR, FPR = calculate_TPR_FPR(thresholdLine, dataROC)\n",
    "\n",
    "    rocX.append(FPR)\n",
    "    rocY.append(TPR)\n",
    "    rocData.append([FPR, TPR])\n",
    "\n",
    "rocData.sort(key=lambda item: (item[0], item[1]), reverse=True)\n",
    "\n",
    "AUC = round(calculateAUC(rocData), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "\n",
    "plt.figure(200)\n",
    "plt.plot(rocX, rocY, marker=\".\", markersize=8)\n",
    "plt.title(\"Winwebsec vs. Zbot LSTM Log Probability ROC\", fontsize=18)\n",
    "plt.xlabel(\"FPR\", fontsize=15)\n",
    "plt.ylabel(\"TPR\", fontsize=15)\n",
    "plt.grid()\n",
    "plt.text(x=0.75, y=0, s=\"AUC: {0}\".format(AUC), fontsize=14, bbox=props)\n",
    "\n",
    "# show plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shutdown:\n",
    "    os.system('shutdown -s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
